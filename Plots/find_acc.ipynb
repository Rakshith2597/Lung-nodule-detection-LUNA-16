{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "from SUMNet_bn import SUMNet\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_itk_image(filename):\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    numpyImage = sitk.GetArrayFromImage(itkimage)\n",
    "   \n",
    "    numpyOrigin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    numpySpacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "    return numpyImage, numpyOrigin, numpySpacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model_loadPath = '/home/siplab/rachana/rak/Results/SUMNet_new/Adam_1e-4_ep100_CE+Lov/'\n",
    "netS = SUMNet(in_ch=1,out_ch=2)\n",
    "netS.load_state_dict(torch.load(seg_model_loadPath+'sumnet_best.pt'))\n",
    "netS = netS.cuda()\n",
    "apply_norm = transforms.Normalize([-460.466],[444.421]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52ffa83aeed4d4bb601e285c04e9fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cand_path = \"/home/siplab/rachana/rak/dataset/candidates.csv\"\n",
    "b_sz = 8\n",
    "df_node = pd.read_csv(cand_path)\n",
    "subset = ['3']#,'5']\n",
    "running_correct = 0\n",
    "count = 0\n",
    "\n",
    "orig_list = []\n",
    "pred_list = []\n",
    "for s in subset:\n",
    "    print('Subset:',s)\n",
    "    luna_subset_path = '/home/siplab/rachana/rak/dataset/subset'+str(s)+'/'    \n",
    "    all_files = os.listdir(luna_subset_path)\n",
    "    mhd_files = []\n",
    "    for f in all_files:\n",
    "        if '.mhd' in f:\n",
    "            mhd_files.append(f)\n",
    "    count = 0\n",
    "    for m in tq(mhd_files):    \n",
    "        mini_df = df_node[df_node[\"seriesuid\"]==m[:-4]]\n",
    "        itk_img = sitk.ReadImage(luna_subset_path+m) \n",
    "        img_array = sitk.GetArrayFromImage(itk_img)\n",
    "        origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "        spacing = np.array(itk_img.GetSpacing())   \n",
    "        slice_list = []\n",
    "        if len(mini_df)>0:\n",
    "            for i in range(len(mini_df)):\n",
    "                fName = mini_df['seriesuid'].values[i]\n",
    "                z_coord = mini_df['coordZ'].values[i]\n",
    "                orig_class = mini_df['class'].values[i]\n",
    "                pred = 0\n",
    "                v_center =np.rint((z_coord-origin[2])/spacing[2])   \n",
    "                img_slice = img_array[int(v_center)]\n",
    "                mid_mean = img_slice[100:400,100:400].mean()    \n",
    "                img_slice[img_slice==img_slice.min()] = mid_mean\n",
    "                img_slice[img_slice==img_slice.max()] = mid_mean\n",
    "                img_slice_tensor = torch.from_numpy(img_slice).unsqueeze(0).float()\n",
    "                img_slice_norm = apply_norm(img_slice_tensor).unsqueeze(0)\n",
    "                \n",
    "                out = F.softmax(netS(img_slice_norm.cuda()),dim=1)\n",
    "                out_np = np.asarray(out[0,1].squeeze(0).detach().cpu().numpy()*255,dtype=np.uint8)\n",
    "\n",
    "                ret, thresh = cv2.threshold(out_np,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                connectivity = 4  \n",
    "                output = cv2.connectedComponentsWithStats(thresh, connectivity, cv2.CV_32S)\n",
    "                stats = output[2]\n",
    "                temp = stats[1:, cv2.CC_STAT_AREA]\n",
    "                if len(temp)>0:\n",
    "                    largest_label = 1 + np.argmax(temp)    \n",
    "                    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "                    max_area = np.max(areas)\n",
    "                    if max_area>150:\n",
    "                        pred = 1\n",
    "                if pred == orig_class:                    \n",
    "                    running_correct += 1\n",
    "                pred_list.append(pred)\n",
    "                orig_list.append(orig_class)\n",
    "                count += 1                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 92.38076137689615\n"
     ]
    }
   ],
   "source": [
    "print('Accuarcy:',(running_correct/count)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(orig_list, pred_list)\n",
    "tn, fp, fn, tp = cf.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50641,  4066],\n",
       "       [  113,    28]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.19858156028368795\n"
     ]
    }
   ],
   "source": [
    "sensitivity = tp/(tp+fn)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9256767872484326\n"
     ]
    }
   ],
   "source": [
    "specificity = tn/(tn+fp)\n",
    "print('Specificity:',specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.006839276990718124\n"
     ]
    }
   ],
   "source": [
    "precision = tp/(tp+fp)\n",
    "print('Precision:',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
